--Amazon DynamoDB is a fully-managed (“serverless”) and NoSQL (nonrelational) database service, available on Amazon Web Services. DynamoDB is highly scalable, meaning you can start really small and grow very big without needing to re-deploy or re-architect. It also offers a flexible model which uses automatic scaling of throughput capacity, this means that it scales compute capacity based on demand, saving money and lowering entry costs. This makes it a great fit for mobile, gaming, IoT, and other high-growth and high-volume applications.
-ADVANTAGES.
Amazon DynamoDB offers multiple advantages over other NoSQL database management systems such as Apache Cassandra and MongoDB. The integration between DynamoDB and other AWS services is especially beneficial. If you are already an AWS user, it’s a great choice.
Simple Set-up
As a serverless database service, setting up is easy. Simply open the AWS Management Console and utilize the wizard. Conversely, in order to set up an on-premises MongoDB instance, you need to follow a long list of instructions and may have to resolve authentication errors.
AWS Security
Security for DynamoDB is governed by AWS Identity and Access Management (IAM). You can also use other AWS security features to enhance the controls. Although MongoDB is secure, there have been security breaches in the past due to improper configuration and management.
What are the costs?
Both DynamoDB and MongoDB are free for a pre-defined period of time. After free usage expires, DynamoDB calculates cost on the basis of reads and writes, while MongoDB calculates cost according to consumed storage.

--Amazon DynamoDB Accelerator (DAX)
DAX is a fully managed, secure, and scalable DynamoDB cache service. It is suitable for read-intensive workloads and provides major improvements in DynamoDB’s response time. DAX clusters are hosted by and run in Amazon Virtual Private Cloud (Amazon VPC). A DAX client should be installed on the Amazon EC2 instance hosting your application in VPC. All requests are routed via the DAX client, which fetches data, if available, from the DAX cluster (a cache hit).
If data is not available in the cluster, it will be extracted from DynamoDB (a cache miss). Results will be provided to your application via the DAX cluster. Caching data in DAX clusters reduces overall read requests on DynamoDB tables, which can save you money. Companies such as Tinder, Expedia, and Genesys all use DAX to enhance the customer experience by providing sub-millisecond response times to customer queries.
Encryption at Rest
Encryption at rest is the newest addition to DynamoDB. To enable it, simply create a new DynamoDB table and uncheck “Use default settings”. Then go to the “Encryption at Rest” section and select “Enable encryption”. AES-256 and AWS Key Management Service (KMS) keys will be used to encrypt the tables and indexes. It is important to note that encryption will not cause latency or performance issues while executing DML and DDL operations.
Scheduled Auto-Scaling
Scheduled auto-scaling leads to a highly available, fault-tolerant, and cost-effective setup. Defining your scaling policy and auto-scaling in DynamoDB is simple once you understand the steps involved.
Global Tables
Global Tables helps developers build highly resilient, multi-region applications. It ensures that data is close to users located in various locations, leading to a reduction in latency. From a developer’s point of view, data updated in a specific region will automatically synchronize with tables located in other regions. However, prices vary for different regions and customers are charged for replicated writes, reads, and storage.
The Low-Down
Amazon DynamoDB has an advantage over other NoSQL databases due to its constant stream of new features and the support from the AWS ecosystem. Being a serverless solution eases a tremendous burden for database administrators. DBAs long had to deal with managing servers and server infrastructure, with serverless computing options they can focus on the database and not the supporting architecture. If you are looking for a NoSQL database service that can deploy quickly, scale easily and deliver on performance, you can be sure it’s a great option.
Comparative Analysis Between Amazon DynamoDB and Other Databases
Compared to other transactional databases, like Oracle, MSSQL, or PostgreSQL, AWS DynamoDB is schemaless, meaning it does not require conformation to a rigid schema of data types, tables, etc. This, though, also comes with a tradeoff: key advantages, like consistently high performance and millisecond latency, are compromised with ACID (atomicity, consistency, isolation, and durability) properties supported by a relational database.

Compared to other NoSQL databases, AWS DynamoDB supports data models like key-value pair (see figure below), and document data structures such as JSON, XML and HTML. But DynamoDB lacks support for columnar data sets, like Cassandra and HBase, and graph models such as Orient DB.
--DynamoDB’s Architecture

AWS products, DynamoDB included, have a reputation as highly available, scalable, and secure. These are some of the keys to its success:
Availability: When your application writes data to an Amazon DynamoDB table and receives a response (such as Okay), all copies of the data are updated. The data will eventually be consistent across all storage locations, usually within one second or less. This is because DynamoDB has a highly redundant architecture with synchronous data replication stored on SSDs for high performance across three facilities or availability zones in a single region.
 Scalability: Automatic partitioning at the database level spreads the data across various partitions and increases the AWS DynamoDB throughput with the growth of the data. To make your life easier, AWS handles this partitioning of data so that customers can concentrate on core aspects.
    Security: DynamoDB can be integrated with AWS’ identity and access management (IAM) to provide each user with unique credentials for accessing database resources. Moreover, access can also be authenticated by leveraging your internal AD or LDAP server. Data is also backed up to Amazon Simple Storage Service (S3) in order to maintain high performance on a massive scale all while preserving durability and security.

How AWS DynamoDB Functions

AWS DynamoDB automatically scales throughput capacity to meet workload demands and partitions and re-partitions your data as your table size grows. Here is how it’s done:
Monitoring: CloudWatch is the central pane for monitoring the performance, resource utilization, and operational health of DynamoDB. CloudWatch keeps an eye on the various metrics and triggers an alarm when a threshold is breached. This can further initiate the auto-scaling of resources per the system’s configuration. (See  Figure 2.)

--RDS VS DM
 DynamoDB is a database service for NoSQL data fully managed by Amazon Web Services. It is swift, reliable, and scalable, which makes working with NoSQL data much easier to handle.
On the other hand, Amazon RDS stands for "Relational Database Service", and we mostly use it for structured and relational data (SQL). Unlike DynamoDB, RDS is the name of the service rather than the database engine itself. So, we can choose from six database engines, including Amazon Aurora, MySQL, and MariaDB
 Attributes for DynamoDB and Amazon RDS
DynamoDB and Amazon RDS are both fully-managed by AWS, thus making the administration more manageable and allowing developers to focus more on using the database service. In addition, both of them are reliable and highly scalable with automated scalability and backup.
The significant difference between these two services is that Amazon RDS is relational, whereas DynamoDB is a NoSQL database engine.
In terms of storage size, DynamoDB stands out with its ability to support tables of any size. But with RDS, the storage size changes based on the database engine we use.
Aurora engine: 128 TB
MySQL, MariaDB, Oracle, PostgreSQL engines: 64 TB
SQL Server engine: 16 TB
Performance of DynamoDB vs Amazon RDS
--DynamoDB
DynamoDB is known for high-performance as it can cope with more than 10 trillion requests within a single day with peaks greater than 20 million requests per second.
There is less latency and response time when reading and writing data because of the high IO performance of SSDs. In addition, the in-memory cache, DynamoDB Accelerator (DAX), can enhance the read performance by ten folds. That can reduce the reading time from milliseconds to microseconds.
No matter the size of the tables you have, the latency of DynamoDB is minimum, and it maintains within milliseconds. So, the performance of this database engine is considerably high, if you use the indexes and partitioning properly.
Amazon RDS
There are two SSD backed options for storage in Amazon RDS. A high-performance choice for OLTP applications and another cost-effective solution for general-purpose use.
The general-purpose solution has a performance that delivers at 3 IOPS per provisioned GB that can scale up to 3000 IOPS. The high-performance option can deliver up to 40000 IOPS per database instance. This high-performance IOPS rate is maintained throughout the lifetime of the database instance.
--Availability and Durability
In DynamoDB, the data is replicated across three availability zones automatically. However, users do not have a choice to choose availability zones, they can only choose a region. The data replication over multiple physical nodes ensures data availability even when power outages or significant natural disasters. Even if one node fails, the data flow will continue with the other nodes without interruption.
Amazon RDS uses Multi-AZ deployments to enhance the availability of its databases. So, in case of any hardware failure, the requested data will be made available by replacing the compute instance powering the database instance with a functional one.
However, it comes optional as the cost also increases, since we need multiple instances(master-slave) in RDS to provide active-passive failover and high availability.
--Security
DynamoDB integrates fairly well with IAM. Since its a cloud-native database offering, it also provides fine-grained access control to limit access using IAM policies. Besides, Amazon RDS also integrates with IAM for authentication for MySQL and PostgreSQL engines.
Encryption with KMS: AWS KMS (Key Management Service) encryption keys ensure DynamoDB security. The KMS allows creating, storing, and managing the encryption keys. There are three options for the users to encrypt the tables with DynamoDB.
AWS-owned key (free and encrypts the key by default)
AWS-managed key (there will be a fee, and stores the key in the user's account)
Customer-managed key (here also, there is a fee, and the user has complete control over the key)
Amazon RDS also uses AWS KMS. These keys are AWS-managed. The users can also use SSL to enhance the security of data.
Comparing Other Features of DynamoDB and Amazon RDS
Backups
PITR (Point-in-time recovery) in DynamoDB provides constant backups, and for the preceding 35 days, the user can restore the database table to any point in time. The performance of the database will not be affected by the data backup and restoration. It is easy and does not interrupt the user's work in any way.
In RDS also, PITR is enabled by the automatic backup for your database instance. The user-initiated backups are stored as database snapshots in Amazon S3 storage until the user intentionally deletes them.
Scalability
Amazon DynamoDB is highly scalable as it can support virtually any table size. It seamlessly scales based on the requirement when the workloads go up and down, reaching traffic levels. The high scalability does not affect the performance. There are two modes the user can pick from,
On-demand
Provisioned capacity mode (the user can set a limit)
Similar to DynamoDB, Amazon RDS is also highly scalable and supports auto-scaling. The procedure is simple, and with just a few clicks, the user can set the auto-scaling maximum capacity. In addition, the user can determine the scalability as on-demand or run with a reserved capacity.
So far, we have discussed comparing the shared attributes of both DynamoDB and Amazon RDS. Now let's see when and where to use the best database solution based on the requirements.
When and Where to Pick Which Database Service
It is essential to determine which database suits you best in your case. So, given below are some use cases for using DynamoDB and Amazon RDS.
Use cases for DynamoDB
There are instances where using relational databases can be costly and complicated. In such cases, the best solution is to opt for NoSQL databases.
When you are already using AWS services, the best NoSQL database model is DynamoDB. It is highly scalable and scaling, or backups do not interrupt the performance. There is no need for manual scaling.
So, this database solution is ideal for systems that require a high speed in data reading and writing. Below are several examples of instances where we can use DynamoDB.
Real-time bidding
Shopping carts
Mobile applications
Content management
High I/O needs
Unstructured data in gaming applications
You can read more about the use cases for DynamoDB here.
Use cases for Amazon RDS
As mentioned above, Amazon RDS is used to store structured and relational data. Therefore, we can use RDS for any relational backend database.
Enterprise applications usually have to have a relational database model because of the nature of storing data. So, in such instances, we cannot use NoSQL databases like DynamoDB. In that case, RDS is a solution for traditional applications, enterprise-grade applications, CRM, and e-commerce solutions. We can also use it in a source system for data warehouses.
Pricing
--DynamoDB
The standard pricing for DynamoDB counts for reading, writing and storage consumed by data. The charges alter based on the additional services the user subscribes. Besides, the way DynamoDB calculates the read and write units is a bit tricky. For reads it takes 4KBs as a single read and 1KB write is taken as a single write unit. Also, there is an effect depending on the GSI's you use in a table.
There are two pricing tiers:
On-demand capacity mode: The payment is calculated based on the application traffic. This option allows the database instance workload to scale up and down as necessary. The user need not specify any throughput. This choice is ideal if you have less predictable database traffic and want to pay for only what you use.
Provisioned capacity mode: In this option, the user must specify the reads and writes per second. If necessary, the user can use auto-scaling to adjust the table size automatically. We can use this solution if the application traffic is predictable and consistent.
Amazon RDS
Amazon RDS charges a monthly amount from the user for each database instance. RDS also comes with a pay-as-you-go model. In addition, there are several pricing tiers based on the database engine (MySQL, Aurora, etc.) and the server capacity we use.
When it comes to pricing, Amazon RDS also has an On-demand pricing model, similar to the DynamoDB. But this is a bit more expensive than the reserved instance pricing available for Amazon Aurora. In reserved instances, the user needs to make the payment on a long term basis, like one or three years.

--REDSHFIT
A Redshift Database is a cloud-based, big data warehouse solution offered by Amazon. The platform provides a storage system that lets companies store petabytes of data in easy-to-access “clusters” that can be queried in parallel.
Each of these nodes can be accessed independently by users and applications. Redshift is designed to be used with a variety of data sources and data analytics tools and is compatible with several existing SQL-based clients.
The platform’s architecture makes it easy to create a Redshift connection to a variety of business intelligence tools.
USES OF REDSHFIT
One of the most effective uses for Redshift databases is in organisations that have a high demand for analytics and access to data.
Thanks to its vertical design for clusters, different departments and teams can have their own node, and easily access others without increasing wait times or causing bottlenecks.
In financial services, Redshift could be used to analyse historical market data or to create predictive models.
Organisations that have variable data needs can also benefit from using Redshift. Nodes can be activated and deactivated on demand, so companies can go from gigabytes to petabyte-level storage in minutes.
One common use for the platform is to store log data for analysis—information that includes web logs, clickstream data, and more. This is useful in marketing and online advertising as well as UX design.
In business intelligence, using a redshift database is useful to generate multiple unique dashboards and allow for better ad hoc analysis.
Companies that collect data from disparate sources and channels can also benefit from Redshift’s modular design, thanks to a variety of connectors and compatibility with SQL and several other database client languages.

--- AWS DMS
AWS DMS is an AWS cloud service created to migrate data in a variety of ways: to the AWS cloud, from on-premises or cloud hosted data stores. AWS DMS can migrate all kinds of data ranging from relational databases, data warehouses, NoSQL databases, and other types of data stores. It is quite versatile and can handle one-time data migration or perform continuous data replication with ongoing changes, syncing the source and target.
Benefits of AWS DMS
The AWS Data Migration Service handles many of the tedious, time-consuming tasks involved in data migration:
AWS DMS is server-less and can deploy, manage and monitor all hardware and software needed for migration automatically so you can avoid conventional tasks like capacity analysis, procurement of hardware and software, system installation and administration and testing/debugging of systems. Technically your migration can be started within minutes of AWS DMS configuration.
AWS DMS allows you to scale migration resources up or down as per requirement. Say if you need more capacity, you can increase storage allocation easily and restart the migration in minutes. Alternatively, if you find you have excess capacity configured, you can downsize as per your reduced workload. 
With AWS DMS you need to pay only for resources you use since it has a pay-as-you-go model unlike traditional licensing plans with up-front purchase costs and ongoing maintenance fees.
AWS DMS provides automated management of the infrastructure associated with your migration server. This covers hardware, software, software patching, and error reporting. AWS DMS Limitations for Oracle Sources
AWS DMS reassures with automatic failover. A backup replication server swings into action if the main replication server fails and takes over with hardly any interruption of service.
AWS DMS can help you change over to a database engine that is modern and makes more financial sense like the managed database services provided by Amazon RDS or Amazon Aurora. AWS DMS can also enable moving to a managed data warehouse like Amazon Redshift, NoSQL platforms like Amazon DynamoDB, or low-cost storage platforms like Amazon S3. If you need to use the same database engine with the modern infrastructure, that is supported too.
Almost all DBMS engines like Oracle, Microsoft SQL Server, MySQL, MariaDB, PostgreSQL, Db2 LUW, SAP, MongoDB, and Amazon Aurora are supported as sources by AWS DMS
AWS DMS covers a wide range of targets including Oracle, Microsoft SQL Server, PostgreSQL, MySQL, Amazon Redshift, SAP ASE, Amazon S3, and Amazon DynamoDB.
AWS DMS enables heterogeneous data migration from any supported data source to any supported target.
Security is built in with an AWS DMS migration. Data at rest is encrypted with AWS KMS encryption (AWS Key Management Service). During migration, (SSL Secure Socket Layers) encrypts your in-flight data as it moves from source to target.
Amazon DMS Components

---Replication instance
A replication instance refers to a managed EC2 instance that hosts replication tasks. Replication instances are of various types:
T2/T3: These are created for configuring, developing, and testing database migration processes. These instances can also be used for periodic migration tasks.
C4: These instances are optimised for performance and suitable for compute-intensive workloads. These instances are appropriate for heterogeneous migrations.
R4/R5: These are memory-optimised instances and should be used for ongoing migrations and high-throughput transactions.
Endpoints
An endpoint is used by the AWS DMS to connect target and source databases and transfer data. The type of endpoint will depend on the database type, but all endpoints generally need the same details such as endpoint type, engine type, encryption protocols, server name, port number, and credentials. AWS ETL Option: AWS Glue Explained
 AWS DMS provides 3 migration type options:
Full Load            
Full Load with AWS DMS migrates all the data in your database at that point, it does not replicate changes in data. This is a good option for a one-time migration and if you do not need to capture ongoing changes. AWS DMS Limitations for Oracle Sources
Full Load + CDC
Full load + CDC is another AWS DMS option that will migrate all your data at the start and then replicate subsequent changes at source too. It will monitor your database while the task is in progress. This is especially good when you have very large databases and do not want to pause workloads. More on Change Data Capture
CDC only             
CDC only with AWS DMS will replicate only changes that have happened in the database, not the initial full load of data. This option is suitable when you are using some other method to transfer your database but still need to sync with ongoing changes at source. 

